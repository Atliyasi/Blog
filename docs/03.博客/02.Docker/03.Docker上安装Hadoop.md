---
title: Docker上安装Hadoop
date: 2024-03-04 22:08:52
permalink: /pages/ee1167/
categories:
  - 博客
  - Docker
tags:
  - Docker
author: 
  name: Atliyasi
  link: https://github.com/Atliyasi
---
# Docker安装Hadoop

## 1.安装前准备

1. Hadoop安装包

这里使用hadoop-2.7.7.tar.gz

2. Docker环境
3. jdk安装包

这里使用jdk-8u202-linux-x64.tar.gz

## 2.配置容器基本环境

#### 1.安装centos

```shell
docker pull centos:centos7.9
```

### 2.创建具有基本环境的centos镜像

```shell
vim ./Dockerfile

# 内容如下

FROM centos
MAINTAINER mwf
# 更换yum源
RUN cd /etc/yum.repos.d/
RUN sed -i 's/mirrorlist/#mirrorlist/g' /etc/yum.repos.d/CentOS-*
RUN sed -i 's|#baseurl=http://mirror.centos.org|baseurl=http://vault.centos.org|g' /etc/yum.repos.d/CentOS-*
# 安装wget
RUN yum -y install wget
# 通过wget更新yum源
RUN wget -O /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-vault-8.5.2111.repo
RUN yum clean all
RUn yum makecache
# 安装ssh
RUN yum install -y openssh
RUN yum install -y openssh-server
RUN sed -i 's/UsePAM yes/UsePAM no/g' /etc/ssh/sshd_config
RUN yum  install -y openssh-clients
# 设置用户密码
RUN echo "root:726400sb" | chpasswd
RUN echo "root   ALL=(ALL)       ALL" >> /etc/sudoers
RUN ssh-keygen -t dsa -f /etc/ssh/ssh_host_dsa_key
RUN ssh-keygen -t rsa -f /etc/ssh/ssh_host_rsa_key

RUN mkdir /var/run/sshd
EXPOSE 22
CMD ["/usr/sbin/sshd", "-D"]
```

![image-20240103205955990](C:\Users\86158\AppData\Roaming\Typora\typora-user-images\image-20240103205955990.png)

```shell
# 创建对应镜像
docker build -t="centos7-ssh" .
```

![image-20240103210144117](C:\Users\86158\AppData\Roaming\Typora\typora-user-images\image-20240103210144117.png)

![image-20240103210223565](C:\Users\86158\AppData\Roaming\Typora\typora-user-images\image-20240103210223565.png)

### 3.创建有hadoop和jdk环境的镜像

```shell
vim ./Dockerfile
# 内容如下
FROM centos7-ssh
ADD jdk-8u202-linux-x64.tar.gz /usr/local/
ENV JAVA_HOME /usr/local/jdk1.8.0_202
ENV PATH $JAVA_HOME/bin:$PATH

ADD hadoop-2.9.2.tar.gz /usr/local
ENV HADOOP_HOME /usr/local/hadoop-2.9.2
ENV PATH $HADOOP_HOME/bin:$PATH

RUN yum install -y which
```

![image-20240103213607955](C:\Users\86158\AppData\Roaming\Typora\typora-user-images\image-20240103213607955.png)

![image-20240103213711846](C:\Users\86158\AppData\Roaming\Typora\typora-user-images\image-20240103213711846.png)

```shell
# 创建镜像
docker build -t="hadoop" .
```

![image-20240103214052226](C:\Users\86158\AppData\Roaming\Typora\typora-user-images\image-20240103214052226.png)

![image-20240103214158886](C:\Users\86158\AppData\Roaming\Typora\typora-user-images\image-20240103214158886.png)

### 4.创建网络，并启动docker容器

```shell
# 创建网络，创建了一个名为hadoop-br的bridge类型的网络
docker network create --driver bridge hadoop-br
```

![image-20240103214538773](C:\Users\86158\AppData\Roaming\Typora\typora-user-images\image-20240103214538773.png)

```shell
# 启动docker容器，并指定网络
docker run -itd --network hadoop-br --name master -p 50070:50070 -p 8088:8088 -p 9000:9000 hadoop-0
docker run -itd --network hadoop-br --name slave1 hadoop-0
docker run -itd --network hadoop-br --name slave2 hadoop-0
```

![image-20240103214746588](C:\Users\86158\AppData\Roaming\Typora\typora-user-images\image-20240103214746588.png)

```shell
# 查看网络
docker network inspect hadoop-br
```

![image-20240103214952002](C:\Users\86158\AppData\Roaming\Typora\typora-user-images\image-20240103214952002.png)

可以得出：

| ip         | 主机名 |
| ---------- | ------ |
| 172.18.0.2 | master |
| 172.18.0.3 | slave1 |
| 172.18.0.4 | slave2 |

### 5.配置域名映射与ssh免密登陆

1.修改主机名(每台都需要修改)（没有必要）

```shell
vi /etc/hostname
```

2.添加域名映射（没有必要）

```shell
vi /etc/hosts
```

![image-20240103220223047](C:\Users\86158\AppData\Roaming\Typora\typora-user-images\image-20240103220223047.png)

3.ssh免密登陆

```shell
# 获取秘钥
ssh-keygen
```

![image-20240103220438464](C:\Users\86158\AppData\Roaming\Typora\typora-user-images\image-20240103220438464.png)

```shell
# 分发秘钥
ssh-copy-id -i /root/.ssh/id_rsa -p 22 root@master
ssh-copy-id -i /root/.ssh/id_rsa -p 22 root@slave1
ssh-copy-id -i /root/.ssh/id_rsa -p 22 root@slave2
```

![image-20240103220516984](C:\Users\86158\AppData\Roaming\Typora\typora-user-images\image-20240103220516984.png)

### 6.配置hadoop

1.配置hadoop sbin环境变量

```shell
vi ~/.bashrc
# 追加
export PATH=$PATH:$HADOOP_HOME/sbin
source ~/.bashrc
```

2.创建配置所需文件夹

```shell
mkdir /home/hadoop
mkdir /home/hadoop/tmp /home/hadoop/hdfs_name /home/hadoop/hdfs_data
```

3.修改配置文件

```xml
# core-site.xml
	<property>
        <name>fs.defaultFS</name>
        <value>hdfs://master:9000</value>
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>file:/home/hadoop/tmp</value>
    </property>
    <property>
        <name>io.file.buffer.size</name>
        <value>131702</value>
    </property>
```

```xml
# hdfs-site.xml
 <property>
        <name>dfs.namenode.name.dir</name>
        <value>file:/home/hadoop/hdfs_name</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>file:/home/hadoop/hdfs_data</value>
    </property>
    <property>
        <name>dfs.replication</name>
        <value>2</value>
    </property>
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>master:9001</value>
    </property>
    <property>
        <name>dfs.webhdfs.enabled</name>
        <value>true</value>
    </property>

```

```xml
# cp mapred-site.xml.template mapred-site.xml
# mapred-site.xml
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <property>
        <name>mapreduce.jobhistory.address</name>
        <value>master:10020</value>
    </property>
    <property>
        <name>mapreduce.jobhistory.webapp.address</name>
        <value>master:19888</value>
    </property>
```

```xml
# yarn-site.xml
 <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <name>yarn.nodemanager.auxservices.mapreduce.shuffle.class</name>
        <value>org.apache.hadoop.mapred.ShuffleHandler</value>
    </property>
    <property>
        <name>yarn.resourcemanager.address</name>
        <value>master:8032</value>
    </property>
    <property>
        <name>yarn.resourcemanager.scheduler.address</name>
        <value>master:8030</value>
    </property>
    <property>
        <name>yarn.resourcemanager.resource-tracker.address</name>
        <value>master:8031</value>
    </property>
    <property>
        <name>yarn.resourcemanager.admin.address</name>
        <value>master:8033</value>
    </property>
    <property>
        <name>yarn.resourcemanager.webapp.address</name>
        <value>master:8088</value>
    </property>
```

```shell
# slaves
slave1
slave2
```

4.拷贝文件

```shell
scp -r ./* slave1:/usr/local/hadoop/etc/hadoop/
scp -r ./* slave2:/usr/local/hadoop/etc/hadoop/
scp -r /home/hadoop slave1:/home/
scp -r /home/hadoop slave2:/home/
```

5.在这里将容器生成镜像

```shell
docker commit 容器id 要生成的镜像名
```

### 7.启动Hadoop

1.格式化hdfs（在master上操作）

```shel
hdfs namenode -forma。
```

2.启动hdfs

```shell
start-dfs.sh
```

3.启动yarn

```shell
start-yarn.sh
```

![image-20240103224536531](C:\Users\86158\AppData\Roaming\Typora\typora-user-images\image-20240103224536531.png)

可以看出来启动成功，接下来查看web界面

![image-20240103224703437](C:\Users\86158\AppData\Roaming\Typora\typora-user-images\image-20240103224703437.png)

![image-20240103224710794](C:\Users\86158\AppData\Roaming\Typora\typora-user-images\image-20240103224710794.png)

完成！

## 3.遇到的问题

1.容器启动的时候一定要提前想好要开放的端口

2.使用已经配置好的镜像重新创建容器后，容器的主机名会发生变化。

3.配置好的镜像已经初始化过了namenode，但是使用该镜像重新创建容器，就会导致namenode不可用，初步推断是由于主机名变化所导致

```shell
# 启动命令
docker run -itd --network hadoop-br --name master -p 50070:50070 -p 8088:8088 -p 9000:9000 master 
docker run -itd --network hadoop-br --name slave1 slave1
docker run -itd --network hadoop-br --name slave2 slave2
```

